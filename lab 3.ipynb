{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "\n",
    "#sentence = [(\"The\", \"DT\"), (\"small\", \"JJ\"), (\"red\", \"JJ\"),(\"flower\", \"NN\"), \n",
    "#(\"flew\", \"VBD\"), (\"through\", \"IN\"),  (\"the\", \"DT\"), (\"window\", \"NN\")]\n",
    "#grammar = \"NP: {?\n",
    "#*}\" \n",
    "#cp = nltk.RegexpParser(grammar)\n",
    "#result = cp.parse(sentence) \n",
    "#print(result)\n",
    "#result.draw()\n",
    "#chunking\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "text =\"Tom should have gone to the dentist yesterday.\".split()\n",
    "print(\"After Split:\",text)\n",
    "tokens_tag = pos_tag(text)\n",
    "print(\"After Token:\",tokens_tag)\n",
    "patterns= \"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
    "chunker = RegexpParser(patterns)\n",
    "print(\"After Regex:\",chunker)\n",
    "output = chunker.parse(tokens_tag)\n",
    "print(\"After Chunking\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = \"My mother is making a cake for my brother\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "tag = nltk.pos_tag(tokens)\n",
    "print(tag)\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "cp  =nltk.RegexpParser(grammar)\n",
    "result = cp.parse(tag)\n",
    "print(result)\n",
    "result.draw()    # It will draw the pattern graphically which can be seen in Noun Phrase chunking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chinking\n",
    "import nltk\n",
    "\n",
    "sentence = [(\"The\", \"DT\"), (\"small\", \"JJ\"), (\"red\", \"JJ\"),(\"flower\", \"NN\"), (\"flew\", \"VBD\"), (\"through\", \"IN\"),  (\"the\", \"DT\"), (\"window\", \"NN\")]\n",
    "\n",
    "grammar = r\"\"\"\n",
    "  NP:\n",
    "    {<.*>+}         # Chunk everything\n",
    "    }+{      # Chink sequences of JJ and NN\n",
    "  \"\"\"\n",
    "chunkprofile = nltk.RegexpParser(grammar)\n",
    "result = chunkprofile.parse(sentence) \n",
    "print(result)\n",
    "result.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name entity recogniton\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(sent)\n",
    "print(cs)\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
